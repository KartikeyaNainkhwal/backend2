# AI-Powered PDF QA System

## ğŸš€ Overview
This project is a **Flask-based AI-powered Question Answering (QA) system** that processes PDF documents and allows users to ask questions based on the content. It uses **LangChain, ChromaDB, Hugging Face embeddings, and Groq's LLaMA 3 model** to provide intelligent responses.

## ğŸŒŸ Features
- ğŸ“„ **PDF Processing** â€“ Extracts text from PDFs using `PyPDFLoader`.
- ğŸ§  **AI-Powered QA** â€“ Uses **LLaMA 3** for answering user queries.
- ğŸ” **Vector Database** â€“ Stores and retrieves document embeddings with **ChromaDB**.
- ğŸš€ **Fast & Scalable** â€“ Efficient embeddings with `HuggingFaceBgeEmbeddings`.
- ğŸŒ **CORS Enabled** â€“ Allows cross-origin requests.

---
## ğŸ› ï¸ Tech Stack
| Category        | Technologies Used |
|----------------|------------------|
| **Backend**    | Flask, Flask-CORS |
| **NLP Model**  | LLaMA 3 via Groq API |
| **Embeddings** | Hugging Face (`all-MiniLM-L6-v2`) |
| **Database**   | ChromaDB |
| **Document Processing** | LangChain, PyPDFLoader |

---
## ğŸ“‚ Project Structure
```bash
project/
â”œâ”€â”€ data/                   # Folder containing PDF files
â”œâ”€â”€ chroma_db/              # Persistent vector database
â”œâ”€â”€ app.py                  # Main Flask application
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # Project documentation
```

---
## âš¡ Getting Started

### 1ï¸âƒ£ Prerequisites
- Install **Python 3.8+**
- Get a **Groq API key**
- Install dependencies

### 2ï¸âƒ£ Installation
```bash
# Clone the repository
git clone https://github.com/your-repo/flask-pdf-qa.git
cd flask-pdf-qa

# Install required dependencies
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run the Application
```bash
python app.py
```
The server will start at `http://127.0.0.1:5000`.

---
## ğŸ”¥ How It Works
1. **Load PDFs** â€“ The system loads all PDFs from the `data/` folder.
2. **Create Vector Database** â€“ Extracts text, splits it into chunks, and generates embeddings.
3. **User Query** â€“ A user sends a query via the `/ask` endpoint.
4. **Retrieve & Answer** â€“ The chatbot finds the most relevant information and responds.

### ğŸ–¥ï¸ API Endpoint
#### `/ask` (POST)
- **Request:** `{ "query": "Your question here" }`
- **Response:** `{ "response": "Answer from the document" }`

---
## ğŸ”§ Configuration
To update the LLM model or embeddings:
- Modify the `initialize_llm()` function for a different **Groq model**.
- Change the `model_name` in `HuggingFaceBgeEmbeddings()` for different **sentence embeddings**.

---
## ğŸ“œ License
This project is licensed under the **MIT License**.

---
## ğŸ“¬ Contact
ğŸ“§ **Email:** your.email@example.com  
ğŸ± **GitHub:** [Your GitHub](https://github.com/KartikeyaNainkhwal)  
ğŸ”— **LinkedIn:** [Your LinkedIn](https://www.linkedin.com/in/kartikeya-nainkhwal-6493402b0/)  

---
### â­ Show Your Support!
If you find this project useful, consider giving it a â­ on GitHub!

